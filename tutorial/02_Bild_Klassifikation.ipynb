{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bild-Klassifizierung\n",
    "\n",
    "Bei der Bild-Klassifizierung identifiziert man das abgebildete Objekt. Objekt-Erkennung kann mithilfe von Bild-Klassifizierung gelöst werden, indem man verschiedene Bildausschnitte klassifizieren lässt. Die mit großer Sicherheit klassifizierten Ausschnitte beinhalten das gesuchte Objekt mit hoher Wahrscheinlichkeit, die anderen können verworfen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Daten vorverarbeten\n",
    "def preprocess_image(x):\n",
    "    # uint8 -> float32\n",
    "    x = x.astype(np.float32)\n",
    "    \n",
    "    # Normalisiere die Bilder (Mean = Null und\n",
    "    #  Standardabweichung = Eins)\n",
    "    x = x - x.mean()\n",
    "    x = x / x.std()\n",
    "    return x\n",
    "\n",
    "def preprocess_label(y):\n",
    "    return y.astype(np.int32)\n",
    "\n",
    "x_train = preprocess_image(x_train)\n",
    "y_train = preprocess_label(y_train)\n",
    "\n",
    "x_test  = preprocess_image(x_test)\n",
    "y_test  = preprocess_label(y_test)\n",
    "\n",
    "x_train.mean(), x_train.std(), y_train.shape, y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitätsmaß\n",
    "\n",
    "Um zu bewerten, wie gut ein Bildklassifizierungs-Algorithmus funktioniert benötigen wir ein Qualitätsmaß. Dazu wird die Genauigkeit (Accuracy) verwendet. Sie ist definiert als $$Genauigkeit = \\frac{Anzahl Richtiger Vorhersagen}{Anzahl Alle Vorhersagen}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    # 'labels' beinhaltet die tatsächliche Klasse jedes Bildes\n",
    "    # 'predictions' beinhaltet unsere vorhergesagte Klasse\n",
    "    \n",
    "    # Wir vergleichen die Vorhersage jedes Bildes mit der \n",
    "    #   tasächlichen Klasse.\n",
    "    # Eg. predictions = [1, 2, 3] und labels = [2, 2, 3]\n",
    "    #   dann ist correct = [False, True, True]\n",
    "    correct = predictions == labels\n",
    "    \n",
    "    # Um damit weiter zu arbeiten müssen wir die Booleans\n",
    "    #  in Zahlen konvertieren [False, True, True] wird\n",
    "    #  dadurch [0, 1, 1]\n",
    "    correct = correct.astype(np.int32)\n",
    "    \n",
    "    # Die Anzahl der korrekten Klassifizierungen ist dann\n",
    "    #   die Summe von 'correct'\n",
    "    number_correct = np.sum(correct)\n",
    "    \n",
    "    # Die Anzahl aller Elemente ist die Länge des Vektors\n",
    "    total = len(correct)\n",
    "    \n",
    "    # Nun können wir die Genauigkeit berechnen:\n",
    "    return number_correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "CIFAR-10 haben wir letztes Tutorial schon kennen gelernt. Die Bilder müssen einer von 10 Klassen zugeordnet werden. Der einfachste Algorithmus ordnet jedem Bild die gleiche Klassen zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Klassifikation\n",
    "\n",
    "# Um für jedes Bild eine Klasse vorherzusagen, müssen wir wissen, wie viele Bilder es gibt:\n",
    "number_of_testimages = len(y_test)\n",
    "print(\"Anzahl der Testbilder: \", number_of_testimages)\n",
    "\n",
    "predicted_class = 0 # Kann jede Zahl innerhalb von [0, 9] sein\n",
    "# Unsere Vorhersage is 'predicted class' für jedes der Bilder\n",
    "y_pred = np.full([number_of_testimages, 1], predicted_class)\n",
    "print(\"Baseline Vorhersage: \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Genauigkeit unsere Baseline Vorhersage\n",
    "print(\"Baseline Genauigkeit: \", accuracy(labels=y_test, predictions=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)\n",
    "\n",
    "Convolutional Neural Networks sind die Grundlage vieler aktueller Bildverarbietungsalgorithmen. Keras macht es sehr einfach CNNs zu erstellen: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.Sequential(\n",
    "    [\n",
    "        # https://keras.io/layers/convolutional/#conv2d\n",
    "        keras.layers.Conv2D(filters=16, kernel_size=(3,3),\n",
    "                            strides=(2,2),\n",
    "                            input_shape=(32, 32, 3)),\n",
    "        # https://keras.io/layers/normalization/#batchnormalization\n",
    "        keras.layers.BatchNormalization(),\n",
    "        # https://keras.io/layers/advanced-activations/#relu\n",
    "        keras.layers.ReLU(),\n",
    "        \n",
    "        # Conv2d -> ReLU -> MaxPooling2D ist ein übliche\n",
    "        # Art und Weise CNNs zu konstruieren\n",
    "        # Diese drei werden (nach belieben) wiederholt\n",
    "        \n",
    "        keras.layers.Conv2D(filters=32, kernel_size=(3,3),\n",
    "                            strides=(2,2)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        \n",
    "        # Jede Convolution mit stride=(2,2) halbiert die \n",
    "        # Bildgröße (von 32x32 auf 16x16 auf 8x8 ... )\n",
    "        \n",
    "        keras.layers.Conv2D(filters=64, kernel_size=(3,3), \n",
    "                            strides=(2,2)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        \n",
    "        # Wenn die Bildgröße sehr klein ist,\n",
    "        #   können wir 'flatten' nutzen, um einen\n",
    "        #   alle übrigen Pixel in einen Vektor zu\n",
    "        #   reihen. Danach produziert eine Dense\n",
    "        #   Layer die letztendliche Klassifikation\n",
    "        \n",
    "        \n",
    "        # https://keras.io/layers/core/#flatten\n",
    "        keras.layers.Flatten(),\n",
    "        # https://keras.io/layers/core/#dense\n",
    "        keras.layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Cross-Entropy-Loss ist ein weiteres Qualitätsmaß für\n",
    "#   Neuronal Netze. Je kleiner es ist, desto besser \n",
    "#   funktioniert das CNN. Es jedoch keine für menschen \n",
    "#   intuitive Einheit, weshalb wir stattdessen die \n",
    "#   Genauigkeit verwenden.\n",
    "# Anders als für die Genauigkeit kann man für die Cross-Entropy\n",
    "#  jedoch die Ableitung berechnen, was es dem CNN erlaub zu\n",
    "#  lernen\n",
    "def loss(y_true, y_pred):\n",
    "    return tf.losses.sparse_softmax_cross_entropy(tf.cast(y_true, tf.int32), \n",
    "                                                  y_pred)\n",
    "\n",
    "# Der Optmizier berechnet neue Gewichte für das CNN, um das\n",
    "#   'loss' zu minimieren.\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=0.001, \n",
    "                                       momentum=0.9)\n",
    "\n",
    "# '.compile' gibt dem CNN alles an die Hand, um es zu trainieren\n",
    "cnn.compile(optimizer=optimizer, \n",
    "            loss=loss,\n",
    "            metrics=[tf.keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das training passiert über die '.fit' Methode, doch zuerst:\n",
    "\n",
    "# wir können nicht mit allen 50'000 Bildern auf einmal arbeiten,\n",
    "#  daher teilen wir alle Daten in 'batches' à 32 Bilder und \n",
    "#  verarbeiten die Daten batch für batch\n",
    "batch_size = 32\n",
    "\n",
    "# Ein Epoch heißt einmal über alle Daten für die Optimierung\n",
    "#  zu benutzen. Je mehr, desto länger dauert das Training, \n",
    "#  aber desto besser kann das CNN werden\n",
    "epochs = 2\n",
    "\n",
    "cnn.fit(x=x_train, y=y_train, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs,\n",
    "        validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Neuronale Netz erreicht 51.62 % Genauigkeit, wir bekommen also jedes zweite Bild korrekt klassifiziert. Es gibt viele Möglichkeiten dies noch weiter zu verbessern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
